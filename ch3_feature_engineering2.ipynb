{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402794de",
   "metadata": {},
   "source": [
    "### seq 컬럼 통계치 추가\n",
    "min, max, mean, std, sum 통계 피처 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf675046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "from src.metrics import toss_metric, lgbm_toss_metric, weighted_log_loss\n",
    "from src.parallel import generate_seq_stats\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40abcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"./data/train_optimized.parquet\")\n",
    "test_df = pd.read_parquet(\"./data/test_optimized.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0362e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating stats features with swifter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab57f2f59bb4b03946b69b19521fd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10704179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating stats features with swifter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9720b64a51d4789a8b9329bf7f331d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1527298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = generate_seq_stats(train_df, col=\"seq\")  # swifter 버전\n",
    "test_df = generate_seq_stats(test_df, col=\"seq\")  # swifter 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20c7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_features = ['seq_len', 'seq_first', 'seq_last', 'seq_max', 'seq_min', 'seq_mean', 'seq_std', 'seq_sum']\n",
    "train_df[stats_features].to_parquet(\"./data/processed/train_seq_stats.parquet\")\n",
    "test_df[stats_features].to_parquet(\"./data/processed/test_seq_stats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454eda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상호작용피처 생성\n",
    "train_df['age_inv_interaction'] = train_df['age_group'].astype(str) + '_' + train_df['inventory_id'].astype(str)\n",
    "test_df['age_inv_interaction'] = test_df['age_group'].astype(str) + '_' + test_df['inventory_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature lists and types updated.\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "bin size 9766 cannot run on GPU",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     36\u001b[39m scale_pos_weight = np.sum(y_train_fold == \u001b[32m0\u001b[39m) / np.sum(y_train_fold == \u001b[32m1\u001b[39m)\n\u001b[32m     38\u001b[39m lgbm = lgb.LGBMClassifier(\n\u001b[32m     39\u001b[39m     objective=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     40\u001b[39m     metric=\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# 커스텀 평가지표 사용\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     verbose=-\u001b[32m1\u001b[39m\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mlgbm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m         \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m         \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlgbm_toss_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m val_preds = lgbm.predict_proba(X_val_fold)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     60\u001b[39m oof_preds[val_idx] = val_preds\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1560\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1557\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1558\u001b[39m             valid_sets.append((valid_x, \u001b[38;5;28mself\u001b[39m._le.transform(valid_y)))\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1574\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:3660\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n\u001b[32m   3659\u001b[39m params_str = _param_dict_to_str(params)\n\u001b[32m-> \u001b[39m\u001b[32m3660\u001b[39m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3661\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3663\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3665\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3666\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3667\u001b[39m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28mself\u001b[39m.train_set = train_set\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: bin size 9766 cannot run on GPU"
     ]
    }
   ],
   "source": [
    "# 피처 및 타겟 정의\n",
    "TARGET = 'clicked'\n",
    "# ID, seq, 타겟을 제외한 모든 컬럼을 피처로 사용\n",
    "features = [col for col in train_df.columns if col not in ['ID', 'seq', TARGET]]\n",
    "categorical_features = [\n",
    "    'gender', 'age_group', 'inventory_id', 'day_of_week', 'hour', \n",
    "    'seq_len', 'seq_first', 'seq_last', 'seq_max', 'seq_min', 'seq_mean', 'seq_std', 'seq_sum',\n",
    "    'age_inv_interaction'\n",
    "]\n",
    "\n",
    "# LightGBM이 카테고리 피처를 인식하도록 타입 변경\n",
    "for col in categorical_features:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "print(\"Feature lists and types updated.\")\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "# 5단계. 모델 학습 및 교차 검증\n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "test_preds = np.zeros(len(test_df))\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"===== Fold {fold+1} =====\")\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # 클래스 불균형 해소를 위한 scale_pos_weight 계산\n",
    "    scale_pos_weight = np.sum(y_train_fold == 0) / np.sum(y_train_fold == 1)\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='none', # 커스텀 평가지표 사용\n",
    "        # device='gpu',              # GPU 사용\n",
    "        # gpu_platform_id=0,         # 기본 GPU 플랫폼\n",
    "        # gpu_device_id=0,           # GPU ID\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_estimators=1000, # 조기 종료를 사용하므로 넉넉하게 설정\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        # 속도 향상을 위한 파라미터\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgbm.fit(X_train_fold, y_train_fold,\n",
    "             eval_set=[(X_val_fold, y_val_fold)],\n",
    "             eval_metric=lgbm_toss_metric,\n",
    "             callbacks=[lgb.early_stopping(100, verbose=True)])\n",
    "    \n",
    "    val_preds = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "    oof_preds[val_idx] = val_preds\n",
    "    \n",
    "    fold_score = toss_metric(y_val_fold, val_preds)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold+1} Score: {fold_score}\")\n",
    "\n",
    "    test_preds += lgbm.predict_proba(test_df[features])[:, 1] / N_SPLITS\n",
    "\n",
    "print(f\"\\nAverage CV Score: {np.mean(cv_scores):.5f} (+/- {np.std(cv_scores):.5f})\")\n",
    "\n",
    "# --- 5. 제출 파일 생성 ---\n",
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['clicked'] = test_preds\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission.to_csv(f'./submissions/submission_{now}.csv', index=False)\n",
    "print(\"Submission file created.\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"y_train\": y_train,\n",
    "    # \"lgbm_baseline_pred\": oof_preds\n",
    "    \"oof_preds\": oof_preds\n",
    "}).to_csv(f\"./oof_preds/oof_preds_{now}.csv\", index=False)\n",
    "print(f\"oof_preds_*.csv created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f40ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "No booster found. Need to call fit beforehand.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 모델 학습이 끝난 후, lgbm 모델 객체로 피처 중요도를 그립니다.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# (CV를 사용했다면, 마지막 fold의 모델이나 모든 fold 모델의 평균을 사용)\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mFeature Importance\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\plotting.py:114\u001b[39m, in \u001b[36mplot_importance\u001b[39m\u001b[34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, importance_type, max_num_features, ignore_zero, figsize, dpi, grid, precision, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m importance_type == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    113\u001b[39m         importance_type = booster.importance_type\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     booster = \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbooster_\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(booster, Booster):\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m importance_type == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1246\u001b[39m, in \u001b[36mLGBMModel.booster_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Booster: The underlying Booster of this model.\"\"\"\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__sklearn_is_fitted__():\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[33m\"\u001b[39m\u001b[33mNo booster found. Need to call fit beforehand.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._Booster\n",
      "\u001b[31mNotFittedError\u001b[39m: No booster found. Need to call fit beforehand."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 학습이 끝난 후, lgbm 모델 객체로 피처 중요도를 그립니다.\n",
    "# (CV를 사용했다면, 마지막 fold의 모델이나 모든 fold 모델의 평균을 사용)\n",
    "plt.figure(figsize=(10, 10))\n",
    "lgb.plot_importance(lgbm, max_num_features=30)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
