{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ceb4f5",
   "metadata": {},
   "source": [
    "### 필요 패키지 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5aa05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from src.pipeline import main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111d0e1",
   "metadata": {},
   "source": [
    "### 임베딩 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb425884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 row_id 개수: 0\n",
      "최종 train shape: (10704179, 128)\n",
      "인덱스 중복 확인: False\n",
      "\n",
      "최종 test.shape (1527298, 128)\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 읽기 및 병합\n",
    "what_columns = \\\n",
    "    [f'mean_{i}' for i in range(64)] \\\n",
    "    # + [f'last_{i}' for i in range(64)] \\\n",
    "    # + ['row_id']\n",
    "\n",
    "# 각 fold 데이터 읽기\n",
    "fold_dfs = []\n",
    "for i in range(5):\n",
    "    fold_path = f'./data/seq_w2v_embedding/embed_valid_fold{i}.parquet'\n",
    "    fold_df = pd.read_parquet(fold_path, columns=what_columns)\n",
    "    fold_dfs.append(fold_df)\n",
    "\n",
    "# 병합 (axis=0으로 행 방향 병합)\n",
    "train_seq_embeddings = pd.concat(fold_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# 메모리 정리\n",
    "del fold_dfs\n",
    "gc.collect()\n",
    "\n",
    "# 2. row_id 기준으로 정렬 및 인덱스 재설정\n",
    "train_seq_embeddings.sort_values(by='row_id', inplace=True)\n",
    "\n",
    "# 3. 중복 row_id 확인 및 처리\n",
    "print(f\"중복 row_id 개수: {train_seq_embeddings['row_id'].duplicated().sum()}\")\n",
    "\n",
    "# 중복이 있다면 처리 (첫 번째 값만 유지)\n",
    "if train_seq_embeddings['row_id'].duplicated().any():\n",
    "    print(\"중복 row_id 제거 중...\")\n",
    "    train_seq_embeddings = train_seq_embeddings.drop_duplicates(subset=['row_id'], keep='first')\n",
    "\n",
    "# 4. row_id를 인덱스로 설정 후 컬럼 제거\n",
    "train_seq_embeddings = train_seq_embeddings.set_index('row_id')\n",
    "\n",
    "# 5. train_df의 인덱스와 일치하도록 재정렬 (필요한 경우)\n",
    "# train_df의 row_id 또는 인덱스 순서와 일치시키기\n",
    "train_seq_embeddings = train_seq_embeddings.reset_index(drop=True)\n",
    "\n",
    "print(f\"최종 train shape: {train_seq_embeddings.shape}\")\n",
    "print(f\"인덱스 중복 확인: {train_seq_embeddings.index.duplicated().any()}\")\n",
    "\n",
    "test_seq_embeddings = pd.read_parquet('./data/seq_w2v_embedding/test/test_ensemble.parquet', columns=what_columns)\n",
    "test_seq_embeddings.drop(columns=['row_id'], inplace=True)\n",
    "\n",
    "print('\\n최종 test.shape', test_seq_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc7ba0",
   "metadata": {},
   "source": [
    "### 통계치 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6eb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_seq_stats.shape (10704179, 8)\n",
      "test_seq_stats.shape (1527298, 8)\n",
      "train_seq_repeat_pattern.shape (10704179, 5)\n",
      "test_seq_repeat_pattern.shape (1527298, 5)\n",
      "train_df.shape (10704179, 119)\n",
      "test_df.shape (1527298, 118)\n",
      "\n",
      " ==============================\n",
      "병합 후\n",
      "==============================\n",
      "train.shape (10704179, 260)\n",
      "test.shape (10704179, 259)\n"
     ]
    }
   ],
   "source": [
    "# ===================================\n",
    "# 1. 데이터 불러오기 및 학습 데이터 준비\n",
    "# ===================================\n",
    "\n",
    "# 1. seq 통계치 데이터 (len, unique_len, first, last, max, min, mean, std)\n",
    "train_seq_stats = pd.read_parquet('./data/seq_stats/train_seq_stats.parquet')\n",
    "test_seq_stats = pd.read_parquet('./data/seq_stats/test_seq_stats.parquet')\n",
    "print('train_seq_stats.shape', train_seq_stats.shape)\n",
    "print('test_seq_stats.shape', test_seq_stats.shape)\n",
    "\n",
    "# 2. seq 반복 패턴 데이터 ('max_streak', 'consecutive_dupe_ratio', 'is_last_in_streak', 'num_unique_streaks', 'avg_streak_length')\n",
    "train_seq_repeat_pattern = pd.read_parquet('./data/seq_repeat_pattern/train_seq_repeat_pattern.parquet')\n",
    "test_seq_repeat_pattern = pd.read_parquet('./data/seq_repeat_pattern/test_seq_repeat_pattern.parquet')\n",
    "print('train_seq_repeat_pattern.shape', train_seq_repeat_pattern.shape)\n",
    "print('test_seq_repeat_pattern.shape', test_seq_repeat_pattern.shape)\n",
    "\n",
    "# 3. train, test 데이터\n",
    "train_df = pd.read_parquet('./data/train_optimized.parquet')\n",
    "test_df = pd.read_parquet('./data/test_optimized.parquet')\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)\n",
    "\n",
    "# 4. 상호작용 데이터 생성\n",
    "train_df['age_inv_interaction'] = train_df['age_group'].astype(str) + '_' + train_df['inventory_id'].astype(str)\n",
    "test_df['age_inv_interaction'] = test_df['age_group'].astype(str) + '_' + test_df['inventory_id'].astype(str)\n",
    "\n",
    "train_df['unique_len_ratio'] = train_df['seq_unique_len'] / train_df['seq_len']\n",
    "test_df['unique_len_ratio'] = test_df['seq_unique_len'] / test_df['seq_len']\n",
    "\n",
    "train_df['unique_len_diff'] = train_df['seq_len'] - train_df['seq_unique_len']\n",
    "test_df['unique_len_diff'] = test_df['seq_len'] - test_df['seq_unique_len']\n",
    "\n",
    "print('\\n', '='*30)\n",
    "print('상호작용 데이터 생성 후')\n",
    "print('='*30)\n",
    "print('train.shape', train_df.shape)\n",
    "print('test.shape', test_df.shape)\n",
    "\n",
    "# 5. 테이블 병합\n",
    "train_df = pd.concat([train_df, train_seq_stats, train_seq_repeat_pattern, test_seq_embeddings], axis=1)\n",
    "test_df = pd.concat([test_df, test_seq_stats, test_seq_repeat_pattern, test_seq_embeddings], axis=1)\n",
    "\n",
    "print('\\n', '='*30)\n",
    "print('병합 후')\n",
    "print('='*30)\n",
    "print('train.shape', train_df.shape)\n",
    "print('test.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6f36be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature types updated.\n",
      "✅ Loaded fold assignments: ./data/seq_w2v_embedding/fold_assign.parquet\n",
      "   Shape: (10704179, 2)\n",
      "   Folds: [4 3 2 0 1]\n",
      "Using saved fold assignments for reproducibility\n",
      "\n",
      "===== Fold 0 =====\n",
      "Train size: 8,563,343, Val size: 2,140,836\n",
      "Scale pos weight: 51.43\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's toss_score: 0.348136\n",
      "Fold 0 Score: 0.34814\n",
      "\n",
      "===== Fold 1 =====\n",
      "Train size: 8,563,343, Val size: 2,140,836\n",
      "Scale pos weight: 51.43\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's toss_score: 0.347671\n",
      "Fold 1 Score: 0.34767\n",
      "\n",
      "===== Fold 2 =====\n",
      "Train size: 8,563,343, Val size: 2,140,836\n",
      "Scale pos weight: 51.43\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's toss_score: 0.347253\n",
      "Fold 2 Score: 0.34725\n",
      "\n",
      "===== Fold 3 =====\n",
      "Train size: 8,563,343, Val size: 2,140,836\n",
      "Scale pos weight: 51.43\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's toss_score: 0.348945\n",
      "Fold 3 Score: 0.34894\n",
      "\n",
      "===== Fold 4 =====\n",
      "Train size: 8,563,344, Val size: 2,140,835\n",
      "Scale pos weight: 51.43\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's toss_score: 0.347937\n",
      "Fold 4 Score: 0.34794\n",
      "\n",
      "============================================================\n",
      "Average CV Score: 0.34799 (+/- 0.00056)\n",
      "============================================================\n",
      "\n",
      "Top 10 Important Features:\n",
      "  seq_len: 2061.0\n",
      "  l_feat_14: 1324.4\n",
      "  seq_mean: 623.2\n",
      "  inventory_id: 345.8\n",
      "  history_a_1: 211.2\n",
      "  age_group: 82.4\n",
      "  feat_c_8: 58.4\n",
      "  history_a_5: 51.4\n",
      "  feat_e_3: 50.0\n",
      "  hour: 48.6\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './raw_data/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m oof_preds, test_preds = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\src\\pipeline.py:225\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(train_df, test_df)\u001b[39m\n\u001b[32m    222\u001b[39m now = datetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# 1. 제출 파일 생성\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m submission = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./raw_data/sample_submission.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m submission[\u001b[33m'\u001b[39m\u001b[33mclicked\u001b[39m\u001b[33m'\u001b[39m] = test_preds\n\u001b[32m    227\u001b[39m submission.to_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./submissions/submission_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pro\\Desktop\\toss\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './raw_data/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "oof_preds, test_preds = main(train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
