{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f624f5",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4030d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df91846",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cbf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'BATCH_SIZE': 4096,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'SEED' : 42\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8939c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b900aa",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901cfb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10704179, 119)\n",
      "Test shape: (1527298, 118)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "all_train = pd.read_parquet(\"./data/train.parquet\", engine=\"pyarrow\")\n",
    "test = pd.read_parquet(\"./data/test.parquet\", engine=\"pyarrow\").drop(columns=['ID'])\n",
    "\n",
    "print(\"Train shape:\", all_train.shape)\n",
    "print(\"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8b4c6",
   "metadata": {},
   "source": [
    "### Data Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f12eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked == 1 데이터\n",
    "clicked_1 = all_train[all_train['clicked'] == 1]\n",
    "\n",
    "# clicked == 0 데이터에서 동일 개수x2 만큼 무작위 추출 (다운 샘플링)\n",
    "clicked_0 = all_train[all_train['clicked'] == 0].sample(n=len(clicked_1)*2, random_state=42)\n",
    "\n",
    "# 두 데이터프레임 합치기\n",
    "train = pd.concat([clicked_1, clicked_0], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce576afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (612537, 119)\n",
      "Train clicked:0: (408358, 119)\n",
      "Train clicked:1: (204179, 119)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Train clicked:0:\", train[train['clicked']==0].shape)\n",
    "print(\"Train clicked:1:\", train[train['clicked']==1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd557ee",
   "metadata": {},
   "source": [
    "### Data Column Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8f41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 117\n",
      "Sequence: seq\n",
      "Target: clicked\n"
     ]
    }
   ],
   "source": [
    "# Target / Sequence\n",
    "target_col = \"clicked\"\n",
    "seq_col = \"seq\"\n",
    "\n",
    "# 학습에 사용할 피처: ID/seq/target 제외, 나머지 전부\n",
    "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
    "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
    "\n",
    "print(\"Num features:\", len(feature_cols))\n",
    "print(\"Sequence:\", seq_col)\n",
    "print(\"Target:\", target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d14898",
   "metadata": {},
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d5e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, seq_col, target_col=None, has_target=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.seq_col = seq_col\n",
    "        self.target_col = target_col\n",
    "        self.has_target = has_target\n",
    "\n",
    "        # 비-시퀀스 피처: 전부 연속값으로\n",
    "        self.X = self.df[self.feature_cols].astype(float).fillna(0).values\n",
    "\n",
    "        # 시퀀스: 문자열 그대로 보관 (lazy 파싱)\n",
    "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
    "\n",
    "        if self.has_target:\n",
    "            self.y = self.df[self.target_col].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float)\n",
    "\n",
    "        # 전체 시퀀스 사용 (빈 시퀀스만 방어)\n",
    "        s = self.seq_strings[idx]\n",
    "        if s:\n",
    "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
    "        else:\n",
    "            arr = np.array([], dtype=np.float32)\n",
    "\n",
    "        if arr.size == 0:\n",
    "            arr = np.array([0.0], dtype=np.float32)  # 빈 시퀀스 방어\n",
    "\n",
    "        seq = torch.from_numpy(arr)  # shape (seq_len,)\n",
    "\n",
    "        if self.has_target:\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "            return x, seq, y\n",
    "        else:\n",
    "            return x, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85983814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(batch):\n",
    "    xs, seqs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    ys = torch.stack(ys)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)  # 빈 시퀀스 방지\n",
    "    return xs, seqs_padded, seq_lengths, ys\n",
    "\n",
    "def collate_fn_infer(batch):\n",
    "    xs, seqs = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
    "    return xs, seqs_padded, seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72644b21",
   "metadata": {},
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a3327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularSeqModel(nn.Module):\n",
    "    def __init__(self, d_features, lstm_hidden=32, hidden_units=[1024, 512, 256, 128], dropout=0.2):\n",
    "        super().__init__()\n",
    "        # 모든 비-시퀀스 피처에 BN\n",
    "        self.bn_x = nn.BatchNorm1d(d_features)\n",
    "        # seq: 숫자 시퀀스 → LSTM\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, batch_first=True)\n",
    "\n",
    "        # 최종 MLP\n",
    "        input_dim = d_features + lstm_hidden\n",
    "        layers = []\n",
    "        for h in hidden_units:\n",
    "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            input_dim = h\n",
    "        layers += [nn.Linear(input_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_feats, x_seq, seq_lengths):\n",
    "        # 비-시퀀스 피처\n",
    "        x = self.bn_x(x_feats)\n",
    "\n",
    "        # 시퀀스 → LSTM (pack)\n",
    "        x_seq = x_seq.unsqueeze(-1)  # (B, L, 1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            x_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h = h_n[-1]                  # (B, lstm_hidden)\n",
    "\n",
    "        z = torch.cat([x, h], dim=1)\n",
    "        return self.mlp(z).squeeze(1)  # logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1746674",
   "metadata": {},
   "source": [
    "### Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a45e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, feature_cols, seq_col, target_col,\n",
    "                batch_size=512, epochs=3, lr=1e-3, device=\"cuda\"):\n",
    "\n",
    "    # 1) split\n",
    "    tr_df, va_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # 2) Dataset / Loader (l_max 인자 제거)\n",
    "    train_dataset = ClickDataset(tr_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "    val_dataset   = ClickDataset(va_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn_train)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn_train)\n",
    "\n",
    "    # 3) 모델\n",
    "    d_features = len(feature_cols)\n",
    "    model = TabularSeqModel(d_features=d_features, lstm_hidden=64, hidden_units=[256,128], dropout=0.2).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 4) Loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xs, seqs, seq_lens, ys in tqdm(train_loader, desc=f\"Train Epoch {epoch}\"):\n",
    "            xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xs, seqs, seq_lens)\n",
    "            loss = criterion(logits, ys)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * ys.size(0)\n",
    "        train_loss /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xs, seqs, seq_lens, ys in tqdm(val_loader, desc=f\"Val Epoch {epoch}\"):\n",
    "                xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "                logits = model(xs, seqs, seq_lens)\n",
    "                loss = criterion(logits, ys)\n",
    "                val_loss += loss.item() * len(ys)\n",
    "        val_loss /= len(val_dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c285a1",
   "metadata": {},
   "source": [
    "### Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80036f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 120/120 [01:13<00:00,  1.63it/s]\n",
      "Val Epoch 1: 100%|██████████| 30/30 [00:11<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.5904 | Val Loss: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████| 120/120 [01:08<00:00,  1.75it/s]\n",
      "Val Epoch 2: 100%|██████████| 30/30 [00:11<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.5740 | Val Loss: 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████| 120/120 [01:06<00:00,  1.80it/s]\n",
      "Val Epoch 3: 100%|██████████| 30/30 [00:11<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.5701 | Val Loss: 0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████| 120/120 [01:09<00:00,  1.72it/s]\n",
      "Val Epoch 4: 100%|██████████| 30/30 [00:11<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.5678 | Val Loss: 0.5670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████| 120/120 [01:12<00:00,  1.65it/s]\n",
      "Val Epoch 5: 100%|██████████| 30/30 [00:11<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.5664 | Val Loss: 0.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|██████████| 120/120 [01:08<00:00,  1.75it/s]\n",
      "Val Epoch 6: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.5647 | Val Loss: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|██████████| 120/120 [01:11<00:00,  1.67it/s]\n",
      "Val Epoch 7: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.5637 | Val Loss: 0.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|██████████| 120/120 [01:11<00:00,  1.67it/s]\n",
      "Val Epoch 8: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.5625 | Val Loss: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|██████████| 120/120 [01:10<00:00,  1.71it/s]\n",
      "Val Epoch 9: 100%|██████████| 30/30 [00:11<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.5615 | Val Loss: 0.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|██████████| 120/120 [01:10<00:00,  1.71it/s]\n",
      "Val Epoch 10: 100%|██████████| 30/30 [00:11<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.5604 | Val Loss: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    train_df=train,\n",
    "    feature_cols=feature_cols,\n",
    "    seq_col=seq_col,\n",
    "    target_col=target_col,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    epochs=CFG['EPOCHS'],\n",
    "    lr=CFG['LEARNING_RATE'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2be60a",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9b9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 373/373 [02:18<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1) Dataset/Loader\n",
    "test_ds = ClickDataset(test, feature_cols, seq_col, has_target=False)\n",
    "test_ld = DataLoader(test_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_infer)\n",
    "\n",
    "# 2) Predict\n",
    "model.eval()\n",
    "outs = []\n",
    "with torch.no_grad():\n",
    "    for xs, seqs, lens in tqdm(test_ld, desc=\"Inference\"):\n",
    "        xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)\n",
    "        outs.append(torch.sigmoid(model(xs, seqs, lens)).cpu())\n",
    "\n",
    "test_preds = torch.cat(outs).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c3f5c",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981b367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['clicked'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'./submissions/submission_{now}.csv'\n",
    "submit.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cbc58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000000</td>\n",
       "      <td>0.300644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0000001</td>\n",
       "      <td>0.327517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0000002</td>\n",
       "      <td>0.249319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0000003</td>\n",
       "      <td>0.279512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0000004</td>\n",
       "      <td>0.184172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527293</th>\n",
       "      <td>TEST_1527293</td>\n",
       "      <td>0.235543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527294</th>\n",
       "      <td>TEST_1527294</td>\n",
       "      <td>0.416566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527295</th>\n",
       "      <td>TEST_1527295</td>\n",
       "      <td>0.142732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527296</th>\n",
       "      <td>TEST_1527296</td>\n",
       "      <td>0.409160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527297</th>\n",
       "      <td>TEST_1527297</td>\n",
       "      <td>0.428927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID   clicked\n",
       "0        TEST_0000000  0.300644\n",
       "1        TEST_0000001  0.327517\n",
       "2        TEST_0000002  0.249319\n",
       "3        TEST_0000003  0.279512\n",
       "4        TEST_0000004  0.184172\n",
       "...               ...       ...\n",
       "1527293  TEST_1527293  0.235543\n",
       "1527294  TEST_1527294  0.416566\n",
       "1527295  TEST_1527295  0.142732\n",
       "1527296  TEST_1527296  0.409160\n",
       "1527297  TEST_1527297  0.428927\n",
       "\n",
       "[1527298 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
